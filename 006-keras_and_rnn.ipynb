{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow教程-keras构建RNN\n",
    "循环神经网络是一种在时间维度上进行迭代的神经网络，在建模序列数据方面有着优越的性能。\n",
    "TensorFlow2中包含了主流的rnn网络实现，以Keras RNN API的方式提供调用。其特性如下：\n",
    "- 易用性： 内置tf.keras.layers.RNN，tf.keras.layers.LSTM，tf.keras.layers.GRU， 可以快速构建RNN模块。\n",
    "- 易于定制：可以使用自定义操作循环来构建RNN模块，并通过tf.keras.layers.RNN调用。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 构建一个简单模型\n",
    "keras中内置了三个RNN层\n",
    "- tf.keras.layers.SimpleRNN，普通RNN网络。\n",
    "- tf.keras.layers.GRU，门控循环神经网络。\n",
    "- tf.keras.layers.LSTM，长短期记忆神经网络。\n",
    "下面是一个循环神经网络的例子，它使用LSTM层来处理输入的词嵌入，LSTM迭代的次数与词个个数一致\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# input_dim是词典大小， output_dim是词嵌入维度\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "# 添加lstm层，其会输出最后一个时间步的输出\n",
    "model.add(layers.LSTM(128))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 输出和状态\n",
    "默认情况下RNN层输出最后一个时间步的输出，输出的形状为(batch_size, units), 其中unit是传给层的构造参数。\n",
    "如果要返回rnn每个时间步的序列，需要置return_sequence=True, 此时输出的形状为(batch_size, time_steps, units)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 128)         74496     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 172,682\n",
      "Trainable params: 172,682\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "# 返回整个rnn序列的输出\n",
    "model.add(layers.GRU(128, return_sequences=True))\n",
    "model.add(layers.SimpleRNN(128))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN层可以返回最后一个时间步的状态。\n",
    "\n",
    "返回的状态可以用于恢复RNN或初始化另一个RNN。此设置通常在seq2seq模型中用到，其将编码器的最终状态作为解码器的初始状态。\n",
    "\n",
    "要使RNN层返回最终的状态需要在创建图层时置return_state=True。请注意，LSTM有两个状态向量，而GRU只有一个。\n",
    "\n",
    "要配置图层的初始状态， 需要网络构建中传入initial_state。其中状态的维度必须与图层的unit大小一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     64000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 194,698\n",
      "Trainable params: 194,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "\n",
    "# 编码层\n",
    "encode_input = layers.Input(shape=(None, ))\n",
    "encode_emb = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encode_input)\n",
    "# 同时返回状态\n",
    "encode_out, state_h, state_c = layers.LSTM(64, return_state=True, name='encoder')(encode_emb)\n",
    "encode_state = [state_h, state_c]\n",
    "\n",
    "# 解码层\n",
    "decode_input =layers.Input(shape=(None, ))\n",
    "decode_emb = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(decode_input)\n",
    "# 编码器的最终状态， 作为解码器的初始状态\n",
    "decode_out = layers.LSTM(64, name='decoder')(decode_emb, initial_state=encode_state)\n",
    "output = layers.Dense(10, activation='softmax')(decode_out)\n",
    "\n",
    "model = tf.keras.Model([encode_input, decode_input], output)\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 RNN层和RNN Cell\n",
    "除了内置的RNN层以外， RNN API还提供单元级API。与可以处理整批次的输入序列不同， RNN Cell仅能处理单个时间步的数据。\n",
    "如果想处理整批次的输入数据，需要将RNN Cell包含在tf.keras.layers.RNN中， 如：RNN(LSTMCell(10)\n",
    "\n",
    "同效果上说， RNN(LSTMCell(10))等价于LSTM(10)。但内置的GRU和LSTM层可以使用CuDNN，以提高计算性能。\n",
    "\n",
    "下面是三个内置的RNN单元， 以及其对应的RNN层。\n",
    "- tf.keras.layers.SimpleRNNCell对应于SimpleRNN图层。\n",
    "- tf.keras.layers.GRUCell对应于GRU图层。\n",
    "- tf.keras.layers.LSTMCell对应于LSTM图层。\n",
    "\n",
    "注： tf.keras.layers.RNN类可以使为研究实现自定义RNN体系结构变得非常容易。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "rnn (RNN)                    (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 97,674\n",
      "Trainable params: 97,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# input_dim是词典大小， output_dim是词嵌入维度\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "# 添加lstm层，其会输出最后一个时间步的输出\n",
    "model.add(layers.RNN(layers.LSTMCell(64)))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 跨批次状态\n",
    "在处理超长序列（有可能无限长）时，可能需要使用到跨批次状态的模式。\n",
    "\n",
    "通常，每次看到新的批次时， 都会重置RNN层的内部状态（state，非权重。即该层看到的每个样本都独立于过去）。\n",
    "\n",
    "但，当序列过长，需要分不同批次输入时，则无需重置RNN的状态(上一批的结束状态，为下一批的初始状态)。这样，即使一次只看到一个子序列，网络层也可以保留整个序列的信息。\n",
    "\n",
    "我们可以置state_ful=True来设置跨批次状态。\n",
    "\n",
    "如果有序列s = [t0, t1, ... t1546, t1547]， 可以将其分为以下批次数据：\n",
    "\n",
    "\n",
    "s1 = [t0, t1, ... t100]\n",
    "\n",
    "s2 = [t101, ... t201]\n",
    "\n",
    "...\n",
    "\n",
    "16 = [t1501, ... t1547]\n",
    "\n",
    "具体调用方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_sequence = []\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "for s in sub_sequence:\n",
    "    output = lstm_layer(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要清除状态时，可以使用layer.reset_states()。\n",
    "\n",
    "注意：在此设置中，i假定给定批次中的样品i是上一个批次中样品的延续。这意味着所有批次应包含相同数量的样本（批次大小）。例如，如果一个批次包含[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]，则下一个批次应包含[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跨批次状态例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": "Fail to find the dnn implementation. [Op:CudnnRNN]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mUnknownError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-3a2076ee6ffc>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mpara3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m20\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mlstm_layer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstateful\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlstm_layer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpara1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlstm_layer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpara2\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlstm_layer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpara3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\anaconda3\\envs\\TensorFlow2-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs, initial_state, constants, **kwargs)\u001B[0m\n\u001B[0;32m    657\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    658\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0minitial_state\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mconstants\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 659\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mRNN\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    660\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    661\u001B[0m     \u001B[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\anaconda3\\envs\\TensorFlow2-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    983\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    984\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menable_auto_cast_variables\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_compute_dtype_object\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 985\u001B[1;33m           \u001B[0moutputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    986\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    987\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_activity_regularizer\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\anaconda3\\envs\\TensorFlow2-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, inputs, mask, training, initial_state)\u001B[0m\n\u001B[0;32m   1174\u001B[0m         \u001B[1;31m# GPU implementation when GPU is available.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1175\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcan_use_gpu\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1176\u001B[1;33m           last_output, outputs, new_h, new_c, runtime = gpu_lstm(\n\u001B[0m\u001B[0;32m   1177\u001B[0m               **gpu_lstm_kwargs)\n\u001B[0;32m   1178\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\anaconda3\\envs\\TensorFlow2-GPU\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001B[0m in \u001B[0;36mgpu_lstm\u001B[1;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\u001B[0m\n\u001B[0;32m   1419\u001B[0m       \u001B[1;31m# Reverse axis 0 since the input is already convert to time major.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1420\u001B[0m       \u001B[0minputs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreverse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1421\u001B[1;33m     outputs, h, c, _ = gen_cudnn_rnn_ops.cudnn_rnn(\n\u001B[0m\u001B[0;32m   1422\u001B[0m         \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_h\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minit_h\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_c\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minit_c\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_training\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1423\u001B[0m         rnn_mode='lstm')\n",
      "\u001B[1;32mD:\\Program Files\\anaconda3\\envs\\TensorFlow2-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\u001B[0m in \u001B[0;36mcudnn_rnn\u001B[1;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001B[0m\n\u001B[0;32m     97\u001B[0m       \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     98\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 99\u001B[1;33m       return cudnn_rnn_eager_fallback(\n\u001B[0m\u001B[0;32m    100\u001B[0m           \u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_h\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_c\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparams\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrnn_mode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mrnn_mode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    101\u001B[0m           \u001B[0minput_mode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minput_mode\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdirection\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdirection\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\anaconda3\\envs\\TensorFlow2-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\u001B[0m in \u001B[0;36mcudnn_rnn_eager_fallback\u001B[1;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\u001B[0m\n\u001B[0;32m    177\u001B[0m   \u001B[1;34m\"direction\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdirection\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"dropout\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdropout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"seed\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseed\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"seed2\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mseed2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    178\u001B[0m   \"is_training\", is_training)\n\u001B[1;32m--> 179\u001B[1;33m   _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n\u001B[0m\u001B[0;32m    180\u001B[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001B[0;32m    181\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0m_execute\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmust_record_gradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Program Files\\anaconda3\\envs\\TensorFlow2-GPU\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mUnknownError\u001B[0m: Fail to find the dnn implementation. [Op:CudnnRNN]"
     ]
    }
   ],
   "source": [
    "para1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "para2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "para3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(para1)\n",
    "output = lstm_layer(para2)\n",
    "output = lstm_layer(para3)\n",
    "lstm_layer.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 双向LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于时间序列以外的序列，比如文本，RNN不仅可以正向处理序列，也可以反向处理序列。例如要预测句子的某个单纯，上下文对单词都有用。\n",
    "\n",
    "Keras提供了tf.keras.layers.Bidirectional的API，构建双向RNN。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True),\n",
    "                              input_shape=(5, 10)))\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在内部， Bidirectional将复制传入的RNN，并将逆序输入新复制的RNN，并输出前向输出和后向输出的叠加。如果想要其他合并行为（如串联），可以修改merge_mode等参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 TensorFlow2.0中的性能优化和CuDNN内核\n",
    "\n",
    "在TensorFlow2.0中，内置的LSTM和GRU层已更新，已在有GPU时默认使用CuDNN内核。通过此更改，先前的keras.layers.CuDNNLSTM/CuDNNGRU层已经弃用，可以简易的构建模型而不必担心其运行的硬件。\n",
    "\n",
    "由于CuDNN内核是根据某些假设构建的，因此如果改变内置LSTM或GRU的默认设置，则该层无法使用CuDNN内核，例如:\n",
    "\n",
    "- 将activation从tanh改为其他激活函数。\n",
    "- 将recurrent_activation由sigmoid改为其他激活函数。\n",
    "- 使recurrent_dropout> 0。\n",
    "- 设置unroll为True，将强制LSTM / GRU将内部分解tf.while_loop为展开的for循环。\n",
    "- 设置use_bias为False。\n",
    "- 当输入数据未严格右填充时使用掩蔽（如果掩码对应于严格右填充数据，则仍可以使用CuDNN。这是最常见的情况）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 在可用时使用CuDNN内核\n",
    "我们构建一个简单的LSTM网络，来实现MNIST数字识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_dim = 28\n",
    "units = 64\n",
    "output_size = 10\n",
    "\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    if allow_cudnn_kernel:\n",
    "        # LSTM默认cudnn加速\n",
    "        lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # LSTMCell内核没有使用\n",
    "        lstm_layer = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(units),\n",
    "                                        input_shape=(None, input_dim))\n",
    "    model = tf.keras.models.Sequential([\n",
    "        lstm_layer,\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnits = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnits.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[0], y_train[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建模型实例并进行编译\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用cudnn的训练\n",
    "model.fit(x_train, y_train,\n",
    "         validation_data=(x_test, y_test),\n",
    "         batch_size=batch_size,\n",
    "         epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在没有CuDNN内核的情况下构建新模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_model = build_model(allow_cudnn_kernel=False)\n",
    "#slow_model.set_weights(model.get_weights())\n",
    "slow_model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer='sgd',\n",
    "             metrics=['accuracy'])\n",
    "slow_model.fit(x_train, y_train,\n",
    "              validation_data=(x_test, y_test),\n",
    "              batch_size=batch_size,\n",
    "              epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用cudnn的模型也可以在cpu环境中进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('CPU:0'):\n",
    "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
    "    cpu_model.set_weights(model.get_weights())\n",
    "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
    "    print('预测结果: %s, 正确标签: %s' % (result.numpy(), sample_label))\n",
    "    plt.imshow(sample, cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.具有列表/字典输入或嵌套输入的RNN\n",
    "嵌套结构可以在单个时间步内包含更多信息。例如，一个视频帧可以同时具有音频和视频输入。比如以下的数据格式：\n",
    "\n",
    "[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]\n",
    "\n",
    "另一个例子，如笔迹数据。可以有当前的位置坐标x，y和压力信息。格式如下：\n",
    "\n",
    "[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]\n",
    "\n",
    "### 7.1 定义一个支持嵌套输入/输出的自定义单元格\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NestedInput = collections.namedtuple('NestedInput', ['feature1', 'feature2'])\n",
    "NestedState = collections.namedtuple('NestedState', ['state1', 'state2'])\n",
    "\n",
    "class NestedCell(tf.keras.layers.Layer):\n",
    "    # 初始化，获取相关参数\n",
    "    def __init__(self,unit1, unit2, unit3, **kwargs):\n",
    "        self.unit1 = unit1\n",
    "        self.unit2 = unit2\n",
    "        self.unit3 = unit3\n",
    "        self.state_size = NestedState(state1=unit1,\n",
    "                                     state2=tf.TensorShape([unit2, unit3]))\n",
    "        \n",
    "        self.output_size = (unit1, tf.TensorShape([unit2, unit3]))\n",
    "        super(NestedCell, self).__init__(**kwargs)\n",
    "    # 构建权重、网络\n",
    "    def build(self, input_shapes):\n",
    "        # input_shape包含2个特征项 [(batch, i1), (batch, i2, i3)]\n",
    "        input1 = input_shapes.feature1[1]\n",
    "        input2, input3 = input_shapes.feature2[1:]\n",
    "        \n",
    "        self.kernel_1 = self.add_weight(\n",
    "            shape=(input1, self.unit1), initializer='uniform', name='kernel_1'\n",
    "        )\n",
    "        self.kernel_2_3 = self.add_weight(\n",
    "            shape=(input2, input3, self.unit2, self.unit3),\n",
    "            initializer='uniform',\n",
    "            name='kernel_2_3'\n",
    "        )\n",
    "    # 前向连接网络\n",
    "    def call(self, inputs, states):\n",
    "        # inputs: [(batch, input_1), (batch, input_2, input_3)]\n",
    "        # state: [(batch, unit_1), (batch, unit_2, unit_3)]\n",
    "        input1, input2 = tf.nest.flatten(inputs)\n",
    "        s1, s2 = states\n",
    "        \n",
    "        output_1 = tf.matmul(input1, self.kernel_1)\n",
    "        output_2_3 = tf.einsum('bij,ijkl->bkl', input2, self.kernel_2_3)\n",
    "        \n",
    "        state_1 = s1 + output_1\n",
    "        state_2_3 = s2 + output_2_3\n",
    "        \n",
    "        output = [output_1, output_2_3]\n",
    "        new_states = NestedState(state1=state_1, state2=state_2_3)\n",
    "        return output, new_states\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 使用嵌套的输入输出构建RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_1 = 10\n",
    "unit_2 = 20\n",
    "unit_3 = 30\n",
    "\n",
    "input_1 = 32\n",
    "input_2 = 64\n",
    "input_3 = 32\n",
    "batch_size = 64\n",
    "num_batch = 100\n",
    "timestep = 50\n",
    "cell = NestedCell(unit_1, unit_2, unit_3)\n",
    "rnn = tf.keras.layers.RNN(cell)\n",
    "input1 = tf.keras.Input((None, input_1))\n",
    "input2 = tf.keras.Input((None, input_2, input_3))\n",
    "outputs = rnn(NestedInput(feature1=input1, feature2=input2))\n",
    "model = tf.keras.models.Model([input1, input2], outputs)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))\n",
    "input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))\n",
    "target_1_data = np.random.random((batch_size * num_batch, unit_1))\n",
    "target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))\n",
    "input_data = [input_1_data, input_2_data]\n",
    "target_data = [target_1_data, target_2_data]\n",
    "\n",
    "model.fit(input_data, target_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}